{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhdKAqEf6Xyp"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdZMFrSVYQ-w"
   },
   "outputs": [],
   "source": [
    "!pip install transformers > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taXLwb9YYD9X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import re\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joEhL1RkYMvG"
   },
   "outputs": [],
   "source": [
    "#DATADIR = \"drive/MyDrive/atma10/input/\"\n",
    "#OUTPUTDIR = \"drive/MyDrive/atma10/feature/\"\n",
    "DATADIR = \"../input/\"\n",
    "OUTPUTDIR = \"../feature/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDX4eriGd0Ca"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2 \n",
    "    dfs = []\n",
    "    for col in df.columns: #columns毎に処理\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: #numericsのデータ型の範囲内のときに処理を実行. データの最大最小値を元にデータ型を効率的なものに変更\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    dfs.append(df[col].astype(np.int8))\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    dfs.append(df[col].astype(np.int16))\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    dfs.append(df[col].astype(np.int32))\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    dfs.append(df[col].astype(np.int64) ) \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    dfs.append(df[col].astype(np.float16))\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    dfs.append(df[col].astype(np.float32))\n",
    "                else:\n",
    "                    dfs.append(df[col].astype(np.float64))\n",
    "        else:\n",
    "            dfs.append(df[col])\n",
    "    \n",
    "    df_out = pd.concat(dfs, axis=1)\n",
    "    if verbose:\n",
    "        end_mem = df_out.memory_usage().sum() / 1024**2\n",
    "        num_reduction = str(100 * (start_mem - end_mem) / start_mem)\n",
    "        print(f'Mem. usage decreased to {str(end_mem)[:3]}Mb:  {num_reduction[:2]}% reduction')\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJ0-brqGVWZJ"
   },
   "outputs": [],
   "source": [
    "def remove_pad_token(s):\n",
    "    if s is np.nan:\n",
    "        return np.nan\n",
    "    \n",
    "    clean_s = re.sub(\"<pad>\", \"\", s)\n",
    "    if clean_s[0] == \" \":\n",
    "        clean_s = clean_s[1:]\n",
    "    return clean_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpWuWwpbYc6j"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATADIR + \"train.csv\")\n",
    "test_data = pd.read_csv(DATADIR + \"test.csv\")\n",
    "\n",
    "all_df = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7UCSCuUYybl"
   },
   "outputs": [],
   "source": [
    "class BertSequenceVectorizer:\n",
    "    def __init__(self):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.model_name = 'bert-base-cased' #uncased  #\"bert-base-multilingual-cased\"\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n",
    "        self.bert_model = transformers.BertModel.from_pretrained(self.model_name)\n",
    "        self.bert_model = self.bert_model.to(self.device)\n",
    "        self.max_len = 128\n",
    "\n",
    "\n",
    "    def vectorize(self, sentence : str) -> np.array:\n",
    "        inp = self.tokenizer.encode(sentence)\n",
    "        len_inp = len(inp)\n",
    "\n",
    "        if len_inp >= self.max_len:\n",
    "            inputs = inp[:self.max_len]\n",
    "            masks = [1] * self.max_len\n",
    "        else:\n",
    "            inputs = inp + [0] * (self.max_len - len_inp)\n",
    "            masks = [1] * len_inp + [0] * (self.max_len - len_inp)\n",
    "\n",
    "        inputs_tensor = torch.tensor([inputs], dtype=torch.long).to(self.device)\n",
    "        masks_tensor = torch.tensor([masks], dtype=torch.long).to(self.device)\n",
    "\n",
    "        bert_out = self.bert_model(inputs_tensor, masks_tensor)\n",
    "        seq_out, pooled_out = bert_out['last_hidden_state'], bert_out['pooler_output']\n",
    "\n",
    "        if torch.cuda.is_available():    \n",
    "            return seq_out[0][0].cpu().detach().numpy() # 0番目は [CLS] token, 768 dim の文章特徴量\n",
    "        else:\n",
    "            return seq_out[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQiAKCACeHiI"
   },
   "outputs": [],
   "source": [
    "BSV = BertSequenceVectorizer() # インスタンス化します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFSkOLnhZC1I"
   },
   "outputs": [],
   "source": [
    "for c in [\"transed_long_title\", \"transed_description\"]:\n",
    "    _df = pd.read_csv(OUTPUTDIR + f\"{c}.csv\") #\"long_title_transed.csv\", \"description_transed.csv\"\n",
    "    all_df = pd.merge(all_df, _df, on=\"object_id\", how=\"left\")\n",
    "    all_df[c] = all_df[c].apply(lambda x: remove_pad_token(x))\n",
    "\n",
    "\n",
    "    all_df[c] = all_df[c].fillna(\"NaN\") # null は代わりのもので埋めます\n",
    "    all_df[f'{c}_feature'] = all_df[c].progress_apply(lambda x: BSV.vectorize(x))\n",
    "\n",
    "    arr = all_df[f\"{c}_feature\"].values.tolist()\n",
    "    arr = np.array(arr)\n",
    "\n",
    "    suffix = \"_\".join(c.split(\"_\")[1:])\n",
    "    df_out = pd.concat([all_df[\"object_id\"],\n",
    "                        pd.DataFrame(arr).add_prefix(f\"nl_enBERT_{suffix}\")], axis=1)\n",
    "\n",
    "    df_out = reduce_mem_usage(df_out)\n",
    "    df_out.to_csv(OUTPUTDIR+f\"nl_en_BERT_{c}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su4K70SCKmZj"
   },
   "outputs": [],
   "source": [
    "#df_out.to_csv(OUTPUTDIR+\"BERT_description.csv\", index=False)\n",
    "#df_out.to_csv(OUTPUTDIR+\"BERT_multi_description.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMe+NKx4F7tCWZSZf2HhRF+",
   "collapsed_sections": [],
   "mount_file_id": "120LAggOoIyTFBxQ4akdIfDju8I67N_zi",
   "name": "text_feature.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
