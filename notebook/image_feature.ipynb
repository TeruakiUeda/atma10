{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhdKAqEf6Xyp"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdZMFrSVYQ-w"
   },
   "outputs": [],
   "source": [
    "!pip install transformers > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "taXLwb9YYD9X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import transformers\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.resnet50 import preprocess_input \n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VpWuWwpbYc6j"
   },
   "outputs": [],
   "source": [
    "#DATADIR = \"drive/MyDrive/atma10/input/\"\n",
    "#OUTPUTDIR = \"drive/MyDrive/atma10/feature/\"\n",
    "DATADIR = \"../input/\"\n",
    "OUTPUTDIR = \"../feature/\"\n",
    "\n",
    "palette = pd.read_csv(DATADIR + \"palette.csv\")\n",
    "\n",
    "train_data = pd.read_csv(DATADIR + \"train.csv\")\n",
    "test_data = pd.read_csv(DATADIR + \"test.csv\")\n",
    "all_df = pd.concat([train_data, test_data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqZi2LHm2RU-"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2 \n",
    "    dfs = []\n",
    "    for col in df.columns: #columns毎に処理\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: #numericsのデータ型の範囲内のときに処理を実行. データの最大最小値を元にデータ型を効率的なものに変更\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    dfs.append(df[col].astype(np.int8))\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    dfs.append(df[col].astype(np.int16))\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    dfs.append(df[col].astype(np.int32))\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    dfs.append(df[col].astype(np.int64) ) \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    dfs.append(df[col].astype(np.float16))\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    dfs.append(df[col].astype(np.float32))\n",
    "                else:\n",
    "                    dfs.append(df[col].astype(np.float64))\n",
    "        else:\n",
    "            dfs.append(df[col])\n",
    "    \n",
    "    df_out = pd.concat(dfs, axis=1)\n",
    "    if verbose:\n",
    "        end_mem = df_out.memory_usage().sum() / 1024**2\n",
    "        num_reduction = str(100 * (start_mem - end_mem) / start_mem)\n",
    "        print(f'Mem. usage decreased to {str(end_mem)[:3]}Mb:  {num_reduction[:2]}% reduction')\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HS_561LQohA6"
   },
   "outputs": [],
   "source": [
    "def extract_features(numpy_img, model):\n",
    "    img = numpy_img.copy()\n",
    "    reshaped_img = img.reshape(1, 224, 224, 3) \n",
    "    img_pp = preprocess_input(reshaped_img)\n",
    "    features = model.predict(img_pp, use_multiprocessing=True) # get the feature vector\n",
    "    features = features.squeeze() \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tf69Rn9zs9sr"
   },
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-1].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9M23NOeWhPa8"
   },
   "outputs": [],
   "source": [
    "exist_palette_list = palette['object_id'].unique().tolist()\n",
    "\n",
    "_all_df = all_df[all_df['object_id'].isin(exist_palette_list)]\n",
    "_all_df = _all_df[[\"object_id\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPlRbjisnCG9"
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    img_width = 224 #512\n",
    "    img_height = 224 #512\n",
    "\n",
    "img_width = Config.img_width\n",
    "img_height = Config.img_height\n",
    "total = img_width * img_height\n",
    "\n",
    "output_list = []\n",
    "for _id, _df in tqdm(palette.groupby(\"object_id\")):\n",
    "    idx_list = len(_df)\n",
    "    prob = _df[\"ratio\"].values\n",
    "    idx = np.random.choice(a=idx_list, \n",
    "                       size=total, \n",
    "                       p=prob)\n",
    "    rgb = _df.iloc[idx][[\"color_r\",\t\"color_g\",\t\"color_b\"]].values\n",
    "    sampling_img = rgb.reshape(img_width, img_height, 3)\n",
    "    feat = extract_features(sampling_img, model)\n",
    "\n",
    "    output = [_id] + feat.tolist()\n",
    "    output_list.append(output)\n",
    "  \n",
    "    #pil_img = Image.fromarray(sampling_img)\n",
    "    #pil_img.save(OUTPUTDIR + f'{_id}.png')\n",
    "    #plt.imshow(sampling_img)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OKzuNDJh7VY"
   },
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(output_list).rename(columns={0:\"object_id\"})\n",
    "df_out = reduce_mem_usage(df_out)\n",
    "df_out.to_pickle(OUTPUTDIR + \"ResNet50_palette_embedding1000.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPmJ3HOyx+aTn2wWo/3P8Sb",
   "collapsed_sections": [],
   "mount_file_id": "1wsayq9Bm1Jmnvt3RYdOESM4vY09ZTDmV",
   "name": "image_feature.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
